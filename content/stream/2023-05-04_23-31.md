---
layout: "post"
date: 2023-05-04T23:31:48-03:00
---

> Cool! I’d expect it to, and I’m sure it can even provide you some really good information. That is, if you know what to ask and know how to interpret what it returns to you. My 10 year old can also provide some very detailed information about what I do for work. About half of what she would say is true, and the rest is generally vauge and plausible enough that, sure, I have trained a shark to help blind people read the web. Why not. My 7 year old just thinks I drink coffee and write emails. Again, partially true. I’m going off topic…

> My point is that this technology is still rather young, and what it regurgitates to you is going to be based on what it’s learned from humans, who are also unfortunately often incorrect. Some may acknowledge these gaps, but still assume ChatGPT could provide people with at least baseline information to start learning about aspects of web accessibility. Or at least, provide you accurate code guidance to help build accessible websites.

> As with the authenticity of my kids’ answers, there is some truth to that, so long as you know that this can give you a start, but you should be mindful and question each answer it provides you

> But, it is going to need some corrective training to help it unlearn all the junk it has picked up so far. I mean, it’s learning from what we’ve written on the Internet. We can’t get upset, and we should KNOW to expect such information gaps and lack of understanding, since its just recycling what we have collectively fed it. It’d be foolish to think it knows better than what it has learned from us.

From [Setting expectations for asking ChatGPT web accessibility questions](https://www.scottohara.me//blog/2023/01/31/ai-a11y-maybe-no.html) by [Scott O'Hara](https://www.scottohara.me/)
