---
layout: "post"
date: 2024-01-06T20:40:15-03:00
---

> A few weeks ago, I stumbled upon a [very cool research project](https://orsonxu.com/wp-content/uploads/publications/CHI20_EarBuddy.pdf) around using the **sound of touch gestures on your face** to create new interactions with interfaces.

> After reading the paper, I decided to try and recreate something similar using JavaScript. I've experimented with using sound data and machine learning in the past and the result was quite successful, however, I had never thought about working with more subtle sounds like the ones this research is focusing on.> 

From [Control UIs using wireless earbuds and on-face interactions](https://charliegerard.dev/blog/control-uis-using-wireless-earbuds-and-on-face-interactions/) by [Charlie Gerard](https://charliegerard.dev/)

Almost all of Charlie's interactions are amazing, and this isnt the exception.
