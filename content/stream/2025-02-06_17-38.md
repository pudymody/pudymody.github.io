---
layout: "post"
date: 2025-02-06T17:38:06-03:00
---

> The need for prompt engineering, on the other hand, puts us back on square one of computer use: the pesky old conundrum of a human user having to think like a computer, instead of the other way around.

> A modern [chess engine](https://en.wikipedia.org/wiki/Stockfish_\(chess\)) can easily outplay even the top ranked chess players of the world. It can be useful for practice and even developing new styles of play, but using one in a chess tournament is considered cheating. Such use is considered cheating for the same reason it's also considered uninteresting: *Humans want to watch human feats*. To most people these days, a computer playing chess comes off as an extremely computery activity. Everyone understands that chess is a closed - albeit complex - system. Everyone also realizes that a modern computer can make deeper, faster and better predictions than any human is capable of. It isn't interesting, impressive or entertaining - at least not the same way a 12 year old human chess prodigy is.

> A computer that can detect a certain type of disease is of course more interesting and beneficial than a highly competent chess engine, and is going to be accepted by the vast majority of humanity as something good. It's not cheating, it's helping. Yet, it's not much to hang a bunch of hype on: Like with a chess engine, or halfway decent machine translation, it's simply a computer finally doing one of the many things we've always been told they should be able to. A one trick pony, basically just another piece of medical software, more like Word or Excel than a thinking machine.

> This also applies to self-driving cars. Driverless vehicles in closed systems have been in use for a long time. The [Copenhagen Metro](https://en.wikipedia.org/wiki/Copenhagen_Metro), for example, has been in operation since 2002 - but like a chess engine, it isn't "AI": it's simply "automated". Currently available software may very well make human drivers both more comfortable and safe, but the hype has promised completely autonomous cars reliably zipping about in rush hour traffic.

> If we're going to be able to use LLMs to replace certain professions, they must at the very least match the average human, yielding consistent, reliable and reproducible results while making fewer and less costly mistakes. And, they should of course be capable of this *without extensive and tedious prompt engineering*. The question of responsibility and liability is a pressing one here, too.

> I may, of course, be completely wrong. Perhaps we'll all soon be replaced by a handful of very small shell scripts interfacing with a distant AI's API. But, deservedly or not, it seems more likely to me that winter is coming.


From [Is Winter Coming? | datagubbe.se](https://www.datagubbe.se/winter/)
